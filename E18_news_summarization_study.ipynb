{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 요약봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비하기\n",
    "\n",
    "- 오늘 우리가 텍스트 요약 모델 학습에 사용할 데이터셋은 Kaggle에서 제공된 아마존 리뷰 데이터셋입니다.\n",
    "- 이번 실습에서는 NLTK의 불용어(stopwords)를 사용할 거에요. NLTK는 Natural Language Toolkit의 축약어로 영어 기호, 통계, 자연어 처리를 위한 라이브러리에요. 이 NLTK에는 I, my, me, over, 조사, 접미사와 같이 문장에는 자주 등장하지만, 의미를 분석하고 요약하는데는 거의 의미가 없는 100여개의 불용어가 미리 정리되어있어요. 이를 이용해 다운로드받은 리뷰 파일에서 불용어를 제거하는 작업을 진행할 예정이에요.\n",
    "- BeautifulSoup 라이브러리도 설치하지 않았다면 설치해주세요. BeautifulSoup는 문서를 파싱하는데 사용하는 패키지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aiffel0042/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "링크에서 다운로드 받은 데이터(Reviews.csv)는 총 568,454개의 샘플을 갖고있어요. 시간상 여기서는 모든 샘플을 사용하지는 않고, 간단히 10만개의 샘플만 사용해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows = 100000)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출력된 샘플수를 보면 총 10만개의 샘플이 잘 불러와진 것을 확인할 수 있습니다. 이 중에 5개만 출력해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "열이 너무 많아서 보기에 조금 까다롭죠. 사실 전체 데이터 중 Summary 열과 Text 열 만 훈련에 사용할 거라, 이 두 개의 열만 별도로 저장하고, 다시 출력해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34642</th>\n",
       "      <td>I like honey mustard but the little bit you ge...</td>\n",
       "      <td>Enough mustard to roll around in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93553</th>\n",
       "      <td>We always order these instead of candies. They...</td>\n",
       "      <td>animal cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99927</th>\n",
       "      <td>The product is great (healthy and perfect tiny...</td>\n",
       "      <td>Charging $9.14 for a $2.99 Sample Size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71254</th>\n",
       "      <td>My daughter takes these to school and loves th...</td>\n",
       "      <td>Great for school snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38394</th>\n",
       "      <td>I switched to this food about two months ago a...</td>\n",
       "      <td>High quality food that helped my dog lose weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28850</th>\n",
       "      <td>My dogs really love this food. Found for a ver...</td>\n",
       "      <td>Dogs love it, and so does my cat!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45359</th>\n",
       "      <td>My family love Walkers Shortbread. They always...</td>\n",
       "      <td>love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89452</th>\n",
       "      <td>Soft drinks and sparkling water drinks rarely ...</td>\n",
       "      <td>A nice pick me up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67963</th>\n",
       "      <td>We have spent 9 years cooking gluten free. We ...</td>\n",
       "      <td>Best Gluten Free Noodles. Period.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31568</th>\n",
       "      <td>I find this to be the best Chai mix.  It is sm...</td>\n",
       "      <td>My favorite Chai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27992</th>\n",
       "      <td>I bought several different brands of Chai from...</td>\n",
       "      <td>Best Chai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79694</th>\n",
       "      <td>First off, for those of you crying about the p...</td>\n",
       "      <td>Great K-Cup Coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40233</th>\n",
       "      <td>TOTALLY agree with the swiss miss suggestion! ...</td>\n",
       "      <td>SUCRALOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48129</th>\n",
       "      <td>I've tried many but this is a great tasting co...</td>\n",
       "      <td>Zico mango coconut water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69145</th>\n",
       "      <td>&lt;a href=\"http://www.amazon.com/gp/product/B000...</td>\n",
       "      <td>Cherry Pie Larabar Reminds Me of Childhood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "34642  I like honey mustard but the little bit you ge...   \n",
       "93553  We always order these instead of candies. They...   \n",
       "99927  The product is great (healthy and perfect tiny...   \n",
       "71254  My daughter takes these to school and loves th...   \n",
       "38394  I switched to this food about two months ago a...   \n",
       "28850  My dogs really love this food. Found for a ver...   \n",
       "45359  My family love Walkers Shortbread. They always...   \n",
       "89452  Soft drinks and sparkling water drinks rarely ...   \n",
       "67963  We have spent 9 years cooking gluten free. We ...   \n",
       "31568  I find this to be the best Chai mix.  It is sm...   \n",
       "27992  I bought several different brands of Chai from...   \n",
       "79694  First off, for those of you crying about the p...   \n",
       "40233  TOTALLY agree with the swiss miss suggestion! ...   \n",
       "48129  I've tried many but this is a great tasting co...   \n",
       "69145  <a href=\"http://www.amazon.com/gp/product/B000...   \n",
       "\n",
       "                                                Summary  \n",
       "34642                 Enough mustard to roll around in.  \n",
       "93553                                    animal cookies  \n",
       "99927            Charging $9.14 for a $2.99 Sample Size  \n",
       "71254                           Great for school snacks  \n",
       "38394  High quality food that helped my dog lose weight  \n",
       "28850                 Dogs love it, and so does my cat!  \n",
       "45359                                           love it  \n",
       "89452                                 A nice pick me up  \n",
       "67963                 Best Gluten Free Noodles. Period.  \n",
       "31568                                  My favorite Chai  \n",
       "27992                                         Best Chai  \n",
       "79694                                Great K-Cup Coffee  \n",
       "40233                                         SUCRALOSE  \n",
       "48129                          Zico mango coconut water  \n",
       "69145        Cherry Pie Larabar Reminds Me of Childhood  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['Text','Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 3개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2개의 열이 남았네요. Text 열의 내용을 요약한 것이 Summary 열이에요. 여기서는 인공 신경망을 통해 Text 시퀀스를 입력받으면, Summary 시퀀스를 예측하도록 인공 신경망을 훈련시킬 거에요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (1) 데이터 정리하기\n",
    "\n",
    "- 중복 샘플과 NULL 값이 존재하는 샘플 제거\n",
    "- 텍스트 정규화와 불용어 제거\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복 샘플과 NULL 값이 존재하는 샘플 제거\n",
    "우선 데이터의 중복 샘플 유무를 확인해 볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복을 제외한다면 Text에는 88,426개, Summary에는 72,348개의 의 유니크한 데이터가 존재해요. 사실 이 데이터의 Summary는 'Smelly'나 'Good Product'와 같이 아주 간단한 요약들도 많아서 Text가 달라도 Summary는 동일할 수 있어요. 하지만 Text 자체가 중복이 된 경우는 중복 샘플이므로 제거해야겠죠.\n",
    "\n",
    "데이터프레임의 drop_duplicates()를 사용하면, 손쉽게 중복 샘플을 제거할 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['Text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복이 제거되면서 샘플수가 88,426개로 줄어들었어요. 그런데 만약 데이터 Null값을 가지는 샘플이 있었다면, drop_duplicates()가 중복된 Null들을 지워주기는 하겠지만, 여전히 Null값 한개가 어딘가 남아있을 수 있어요. 데이터에 Null 값이 남아있는지 볼게요.\n",
    "\n",
    "데이터프레임에 Null 값이 있는지 확인하는 방법은 .isnull().sum()을 사용하면 알아볼 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary에 1개의 Null 값이 있네요. 데이터프레임에서 Null을 제거할대는 dropna()함수를 사용하면 돼요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 샘플수가 1개 줄어들어 88,425개의 샘플이 남았네요. 지금까지 중복 샘플과 Null 값이 있는 샘플들을 제거해보았는데 10만개의 샘플 중 1만개 이상의 샘플이 제거되었어요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  텍스트 정규화와 불용어 제거\n",
    "\n",
    "살아남은 88,425개의 샘플에는 수많은 단어들이 있어요. 그런데 사실 그 단어들 중에서는 같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우가 있어요.\n",
    "\n",
    "예를 들어서 'it'll'은 'it will'과 같고, 'mustn't과 'must not'은 사실 같은 표현이죠. 이런 경우 기계가 굳이 이들을 마치 다른 단어로 간주하게 해서 연산량을 늘리는 것보다는 기계 학습 전에 미리 같은 표현으로 통일시켜주는 것이 기계의 연산량을 줄일 수 있는 방법이에요.\n",
    "\n",
    "이러한 방법론을 텍스트 처리에서는 텍스트 정규화(text normalization)라고 해요.\n",
    "\n",
    "여기서는 텍스트 정규화를 위한 사전(dictionary)을 아래와 같이 구성할거에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 정규화 준비까지 마쳤어요.\n",
    "\n",
    "하지만 아직 끝난게 아니에요. 일반적으로 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별 도움이 되지 않는 단어들이 존재해요. 이를 불용어(stopwords)라고 불러요. 때로는 불용어를 제거하는 것이 자연어 처리의 성능을 높이는 방법일 수 있어요. 여기서는 NLTK에서 제공하는 불용어 리스트를 참조해, 샘플에서 불용어를 제거할 거에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK에서 미리 정의하여 제공하고 있는 불용어는 총 179를 볼 수 있죠. 이를 사용하여 불용어를 제거할거에요. 이 작업 외에도 모든 영어문자는 소문자로 만들고, 섞여있는 html 태그를 제거하고, 정규 표현식을 통해 각종 특수문자를 제거해서 정말 필요한 내용만 잘 학습할 수 있도록 처리할거에요.\n",
    "\n",
    "함수의 하단을 보면, NLTK를 이용해 불용어를 제거하는 파트가 있는데, 이는 Text 전처리 시에서만 호출하고 이미 상대적으로 문장 길이가 짧은 Summary 전처리할 때는 호출하지 않을 예정이에요. Abstractive한 문장 요약 결과문이 자연스러운 문장이 되려면 이 불용어들이 Summary에는 남아 있는게 더 좋을 것 같습니다. 이 처리를 위해서 함수의 인자로 remove_stopwords를 추가하고, if문을 추가했어요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 전, 후의 결과를 확인하기 위해서 임의의 text와 summary를 만들어 함수를 호출해볼까요. parser를 설치하기 위해서, lxml을 설치해주세요.\n",
    "- $pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 보면 기본적으로 모든 알파벳이 소문자로 변환되고,\n",
    "과 같은 html 태그가 제거되었죠. 또한 (or finish)와 같은 괄호로 묶였던 단어 시퀀스가 제거된 것도 확인할 수 있어요. 그리고 특수문자가 제거되면서 영어만 남았어요.\n",
    "\n",
    "이제 함수가 잘 작동하는 것을 확인했으니, 훈련 데이터 전체에 대해서 전처리를 수행해볼게요. 이때, Text의 경우에는 불용어를 제거하고, Summary의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출해서 진행해야해요. 먼저 Text를 전처리하고, 결과를 확인하기 위해서 상위 5개의 줄을 출력해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Summary에 대해서 전처리 함수를 호출해줄 때는, 불용어 제거를 수행하지 않는다는 의미에서 두번째 인자로 False를 넣어줄게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_summary = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "clean_summary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 텍스트 정제의 과정을 거친 후에는 다시 한번 빈(empty) 샘플이 생겼는지 확인해보는 것이 좋아요. 정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있어요. 이렇게 되면 샘플 자체가 빈 값을 가지게 되겠죠.\n",
    "\n",
    "보다 쉽게 확인하기 위해 데이터들을 데이터프레임에 재저장할게요. 그리고 빈(empty) 값을 가진 샘플들이 있다면, 모두 Null 값을 가진 샘플로 대체해요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전과 같이 .isnull().sum()을 사용해서 Null 값이 생겼는지 해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary 열에서 70개의 Null 값이 생겼네요. 원래는 단어가 있었는데, 정제 과정에서 모든 단어가 제거되어 빈 샘플이 70개나 생겼다는 의미에요. 이 샘플들은 모두 제거해줄게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :',(len(data)))#데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (2) 훈련데이터와 테스트데이터 나누기\n",
    "\n",
    "학습을 진행하기 위해서는 학습에 사용할 데이터의 크기를 결정하고, 문장의 시작과 끝을 표시 해줘야해요\n",
    "\n",
    "### 샘플의 최대 길이 정하기\n",
    "\n",
    "필요없는 단어를 모두 솎아낸 데이터를 가지게 되었으니, 이제 훈련에 사용할 샘플의 최대 길이를 정해줄 차례에요.\n",
    "\n",
    "Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화해서 볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of text')\n",
    "plt.ylabel('number of textles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프처럼, 많은 양의 데이터를 다룰때는 데이터를 시각화하여 보는 것이 도움이 돼요. 위에서 부터 차례대로 그래프는 각각 요약과 실제 텍스트의 길이 분포, 요약본 샘플 길이별 갯수, 실제 텍스트 샘플 길이별 갯수를 나타내고 있어요.\n",
    "\n",
    "Text의 경우 최소 길이가 2, 최대 길이가 1,235으로 그 차이가 굉장히 크죠. 하지만 평균 길이는 38로 시각화 된 그래프로 봤을 때는 대체적으로는 100 내외의 길이를 가진다는 것을 확인할 수 있어요.\n",
    "\n",
    "Summary의 경우 최소 길이가 1, 최대 길이가 28, 그리고 평균 길이가 4로 Text에 비해 상대적으로 길이가 매우 짧아요. 그래프로 봤을 때에도 대체적으로 10이하의 길이를 가지고 있네요.\n",
    "\n",
    "이로부터 Text의 최대 길이와 Summary의 적절한 최대 길이를 임의로 정해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 50과 8로 정했는데 이 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인하는 편이 객관적으로 길이를 결정하는데 도움이 될거에요. 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수를 만들어서 좀 더 정확하게 판단해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 만든 함수를 Text와 Summary에 적용해 우리가 결정한 임의의 길이가 몇%의 샘플까지 포함하는지 볼 수 있겠죠.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각 50과 8로 패딩을 하게되면 해당 길이보다 긴 샘플들은 내용이 잘리게 되는데, Text 열의 경우에는 약 23%의 샘플들이 내용이 망가지게 된다고 하네요.\n",
    "\n",
    "우리는 정해진 길이에 맞춰 자르는 것이 아니라, 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제할게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시작 토큰과 종료 토큰 추가하기\n",
    "앞서 시작 토큰과 종료 토큰에 대해서 언급했던 것을 기억하시나요? 디코더는 시작 토큰을 입력받아 문장을 생성하기 시작하고, 종료 토큰을 예측한 순간에 문장 생성을 멈추는 거였죠.\n",
    "\n",
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있어요. 이번 실습에서는 시작 토큰은 'sostoken', 종료 토큰은 'eostoken'이라 임의로 명명하고 앞, 뒤로 추가할거에요. 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 decoder_input, 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 decoder_target이라고 이름을 정했어요. 두 개의 문장 모두 Summary 열로부터 만들거에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞뒤로 토큰이 잘 붙었죠? 인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장해줄게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 훈련 데이터와 테스트 데이터를 분리할거에요.\n",
    "\n",
    "훈련 데이터와 테스트 데이터를 분리하는 방법은 분리 패키지를 사용하는 방법, 또는 직접 코딩을 통해서 분리하는 방법 등 여러가지 방법이 있을텐데 여기서는 직접 해볼게요. 우선, encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들어줄게요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20961 40710 33577 ... 31179 45664 14180]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해주면 잘 섞인 샘플이 되겠죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리해줄게요. 전체 데이터의 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정의해줄게요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 정의한 테스트 데이터의 갯수를 이용해 전체 데이터를 양분할게요. :표시의 위치에 주의해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터가 각각 52,654개와 13,163개로 잘 분리된 것을 볼 수 있어요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기 (3) 정수 인코딩\n",
    "단어 집합(vocaburary) 만들기 및 정수 인코딩\n",
    "이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꾸어 주어야 해요. 이를 위해서는 각 단어에 고유한 정수를 맵핑하는 작업이 필요해요. 이 과정을 단어 집합(vocaburary)을 만든다고 표현해요. 훈련 데이터에 대해서 단어 집합을 만들어볼게요. 우선, 원문에 해당되는 encoder_input_train에 대해서 단어 집합을 만들게요.\n",
    "\n",
    "Keras의 토크나이저를 사용하면, 입력된 훈련 데이터로부터 단어 집합을 만들 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었어요. 현재 생성된 단어 집합은 src_tokenizer.word_index에 저장되어있어요. 그런데 우리는 이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, 빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행하려고 해요.\n",
    "\n",
    "등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해볼게요.\n",
    "\n",
    "src_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장되어져 있는데, 이를 통해서 통계적인 정보를 얻을 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31873\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23637\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8236\n",
      "단어 집합에서 희귀 단어의 비율: 74.15994729081041\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.3935323877538464\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder_input_train에는 총 32,031개의 단어가 있네요. 그 아래의 통계 정보들을 해석해볼까요?\n",
    "\n",
    "등장 빈도가 threshold 값인 7회 미만, 즉, 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지하네요. 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39%밖에 되지 않아요.\n",
    "\n",
    "그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 합니다. 위에서 이를 제외한 단어 집합의 크기를 8,233으로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8000으로 제한해볼게요. 토크나이저를 정의할 때 num_words의 값을 정해주면, 단어 집합의 크기를 제한할 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행해요. 현재 단어 집합의 크기를 8,000으로 제한했으니까 이제 8,000이 넘는 숫자들은 정수 인코딩 후에는 데이터에 존재하지 않아요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[163, 5063, 2707, 490, 1598, 4, 206, 1674, 1101, 1095, 4383, 458, 614, 32, 386, 950, 13, 832, 989, 6142, 6803, 630, 367, 163, 175, 25, 2394, 51, 1323, 80, 322], [78, 48, 8, 13, 15, 1433, 14, 15, 9, 1862, 121, 46, 216], [160, 112, 204, 64, 1544, 184, 9, 123, 9, 465, 41, 171, 1060, 2164, 235, 538, 1185, 45, 1544, 271, 1, 109, 42, 247, 2204, 541, 202, 67, 208, 18, 137, 224, 345]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 더 이상 텍스트 데이터가 아니라 정수가 나오고 있어요.\n",
    "\n",
    "Summary 데이터에 대해서도 동일한 작업을 수행할게요. 케라스의 토크나이저를 사용하여 decoder_input_train을 입력으로 전체 단어 집합과 각 단어에 대한 빈도수를 계산해요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었어요. 이는 tar_tokenizer.word_index에 저장되어있어요. tar_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장되어져 있는데, 이를 통해서 통계적인 정보를 얻어서, 등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10492\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8108\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2384\n",
      "단어 집합에서 희귀 단어의 비율: 77.27792603888676\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.869629718816785\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "등장 빈도가 5회 이하인 단어들은 단어 집합에서 약 77%를 차지하고있네요. 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 5.89%밖에 되지 않아요. 아까 했던것과 동일하게 이 단어들은 모두 제거할게요. 2,382에서 어림잡아 2,000을 단어 집합의 크기로 제한할게요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 9, 15, 77, 46, 31], [1, 344, 11, 1284], [1, 12, 19, 93, 4, 7, 1212], [1, 89, 1965, 163], [1, 242, 1058, 19, 5, 8]]\n",
      "target\n",
      "decoder  [[9, 15, 77, 46, 31, 2], [344, 11, 1284, 2], [12, 19, 93, 4, 7, 1212, 2], [89, 1965, 163, 2], [242, 1058, 19, 5, 8, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정상적으로 정수 인코딩 작업이 끝났어요. 현재 decoder_input_train과 decoder_target_train에는 더 이상 숫자 2,000이 넘는 숫자들은 존재하지 않아요. 그런데 다음 작업인 패딩하기로 넘어가기 전에 한 가지 점검해야할 것이 있어요.\n",
    "\n",
    "전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었을 가능성이 있어요. 이 현상은 길이가 상대적으로 길었던 원문(Text)의 경우에는 문제가 별로 없겠지만, 애초에 평균 길이가 4밖에 되지 않았던 요약문(Summary)의 경우에는 이 현상이 굉장히 두드러졌을 가능성이 높겠죠.\n",
    "\n",
    "요약문에서 길이가 0이 된 샘플들의 인덱스를 받아와볼게요. 여기서 주의할 점은 요약문인 decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제 되지 않아요. 그래서 이제 길이가 0이 된 요약문의 실제길이는 1로 나올거에요. 길이 0이 된 decoder_input에는 sostoken, decoder_target에는 eostoken만 남아 있을테니까요.\n",
    "\n",
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장해볼게요. 이 샘플들은 모두 삭제할거에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1243\n",
      "삭제할 테스트 데이터의 개수 : 345\n",
      "훈련 데이터의 개수 : 51412\n",
      "훈련 레이블의 개수 : 51412\n",
      "테스트 데이터의 개수 : 12818\n",
      "테스트 레이블의 개수 : 12818\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터 모두 일정량의 샘플들이 제거된 것을 확인할 수 있어요. 이제 거의 다 왔어요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩하기\n",
    "\n",
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해주어야 해야해요. 아까 정해두었던 최대 길이로 패딩해 줄 거에요. 최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춰줄게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 학습에 필요한 데이터 전처리가 모두 끝났어요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 설계하기\n",
    "이제는 모델을 설계할 시간이에요. 우선 함수형 API를 이용해서 인코더를 설계해 볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256으로 정의했어요. hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터에요. 이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴론의 갯수라고 이해하면 돼요. 다른 신경망과 마찬가지로, 무조건 용량을 많이 준다고 해서 성능이 반드시 올라가는 것은 아니에요.\n",
    "\n",
    "인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였어요. hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있죠. 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내줘야겠죠?\n",
    "\n",
    "디코더를 설계해볼게요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일해요. 하지만 LSTM의 입력을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어줘야 해요.\n",
    "\n",
    "디코더의 출력층을 설계해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코더의 출력층에서는 Summary의 단어장인 tar_vocab의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야 해요. 그렇기 때문에 Dense의 인자로 tar_vocab을 주고, 활성화 함수로 소프트맥스 함수를 사용하고 있어요.\n",
    "\n",
    "지금까지 설계한 것은 인코더의 hidden state와 cell state를 디코더의 초기 state로 사용하는 가장 기본적인 seq2seq에요. 그런데 디코더의 출력층을 설계를 살짝 바꿔서 성능을 높일 수 있는 방법이 있어요! 바로 어텐션 메커니즘이에요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어텐션 매커니즘\n",
    "\n",
    "어텐션 메커니즘을 수행하는 어텐션 함수를 설계하는 것은 또 다른 새로운 신경망을 설계해야한다는 뜻이에요. 어텐션 함수를 설계해보는 것은 다음 기회로 미루기로 하고, 여기서는 이미 구현된 어텐션 함수를 가져와서 디코더의 출력층에 어떤 방식으로 결합하는지 배워볼게요.\n",
    "\n",
    "아래의 코드를 수행하여 깃허브에 공개되어져 있는 어텐션 함수를 다운로드 할게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 경로에 attention.py 파일이 생겼으니, 어텐션 메커니즘을 사용할 준비가 되었어요. 설계한 디코더의 출력층을 다음과 같이 수정할게요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드는 인코더의 hidden state들과 디코더의 hidden state들을 어텐션 함수의 입력으로 사용하고, 어텐션 함수가 리턴한 값을 예측 시에 디코더의 hidden state와 함께 활용하는 형태로 작동하고 있어요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 훈련하기\n",
    "설계한 모델을 가지고 훈련을 진행해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 55s 274ms/step - loss: 2.7007 - val_loss: 2.4078\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 55s 274ms/step - loss: 2.3849 - val_loss: 2.2687\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 55s 273ms/step - loss: 2.2470 - val_loss: 2.1725\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 56s 280ms/step - loss: 2.1317 - val_loss: 2.0620\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 56s 280ms/step - loss: 2.0388 - val_loss: 2.0059\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 56s 280ms/step - loss: 1.9717 - val_loss: 1.9608\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 56s 279ms/step - loss: 1.9168 - val_loss: 1.9387\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 56s 281ms/step - loss: 1.8705 - val_loss: 1.9049\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 56s 277ms/step - loss: 1.8291 - val_loss: 1.8886\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 56s 281ms/step - loss: 1.7917 - val_loss: 1.8757\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 56s 280ms/step - loss: 1.7575 - val_loss: 1.8642\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 56s 281ms/step - loss: 1.7267 - val_loss: 1.8571\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 56s 278ms/step - loss: 1.6970 - val_loss: 1.8483\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 56s 277ms/step - loss: 1.6702 - val_loss: 1.8467\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 56s 277ms/step - loss: 1.6447 - val_loss: 1.8431\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 55s 275ms/step - loss: 1.6211 - val_loss: 1.8397\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 56s 276ms/step - loss: 1.5967 - val_loss: 1.8359\n",
      "Epoch 18/50\n",
      "201/201 [==============================] - 55s 276ms/step - loss: 1.5737 - val_loss: 1.8389\n",
      "Epoch 19/50\n",
      "201/201 [==============================] - 55s 274ms/step - loss: 1.5513 - val_loss: 1.8399\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EarlyStopping은 한국어로 해석 하면 '조기 종료'의 뜻을 가지고 있는데, 특정 조건이 충족되면 모델의 훈련을 멈추는 역할을 해요. 여기서는 val_loss(검증 데이터의 손실)을 모니터링 하면서, 검증 데이터의 손실이 줄어들지 않고 증가하는 현상이patiensce =2 2회 관측되면 학습을 멈추도록 설정되어져 있어요. 26번째 epoch쯤에서 조기종료되네요.\n",
    "\n",
    "훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정을 시각화 해봐요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인퍼런스 모델 구현하기\n",
    "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 아래와 같이 미리 준비해 둡니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 한다는 것, 알고 계시나요?\n",
    "\n",
    "훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한번에 비교할 수 있으므로, 인코더와 디코더를 엮은 통짜 모델 하나만 준비했습니다.\n",
    "\n",
    "그러나 정답 문장이 없는 인퍼런스 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에 부득이하게 인퍼런스를 위한 모델 설계를 별도로 해주어야 합니다. 이때는 인코더 모델과 디코더 모델을 분리해서 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어텐션 메커니즘을 사용하는 출력층을 설계해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인퍼런스 단계에서 단어 시퀀스를 완성하는 함수를 만들어주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 테스트하기\n",
    "테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인하는 것이 편하겠죠. 주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어볼게요. 함수를 만들 때, Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외시키고 Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외시키도록 만들거에요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : haribo name says quality made germany better gummi bears lover colorful bears enjoy pounds look high quality gummi products cannot go wrong haribo ones soft juicy addictive \n",
      "실제 요약 : would give stars if could \n",
      "예측 요약 :  the best gummi bears ever\n",
      "\n",
      "\n",
      "원문 : sitting watching enjoying latte national giving praise espresso ground great moved california dissapointed affordable coffee nyc missed peet tops flavor body godsend arrive fresh ready go thanks \n",
      "실제 요약 : great taste of home \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : looking however using cuisinart leak back water different areas cup area want ruin machine trying different things disposable cup smaller amount coffee packing smaller amount water cup size still leaks getting better areas dripping water coffee hitting inside coffee cup several outside coffee cup \n",
      "실제 요약 : cups disposable \n",
      "예측 요약 :  good stuff\n",
      "\n",
      "\n",
      "원문 : great agave portable format difficult open directions say pinch open easy pinch found bend tube inch end pinch end helps agave often gets fingers \n",
      "실제 요약 : agave nectar \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : quite possibly best brownie mix money buy little hesitant buying groceries amazon say happy outcome \n",
      "실제 요약 : right product on time delivery \n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : shih tzu seven one greenie day years happy healthy great teeth begs greenie every morning worry greenies causing allergies main source allergies corn dog food little one favor go grain free reduced grain dog food think wild dogs eat corn meal little one allergies amazed immediate healing \n",
      "실제 요약 : wonderful treat \n",
      "예측 요약 :  greenies are the best\n",
      "\n",
      "\n",
      "원문 : spread lobster cream cheese bad really salty look consistency cat food spread crackers saltiness next time think spread bread \n",
      "실제 요약 : too salty \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : mccann oatmeal every morning ordering amazon able save almost per box great product tastes great healthy \n",
      "실제 요약 : food great \n",
      "예측 요약 :  great cereal\n",
      "\n",
      "\n",
      "원문 : brew double cup one kcup still nice strong cups like cup pod store ziploc baggie love great price great coffee \n",
      "실제 요약 : nice and strong \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : two siamese kittens mostly canned food diet chicken salmon formula one foods current rotation seem really enjoy eating although would say favorite food see bits ingredients food texture firm certainly firm pate style food already ordered second case plan order future oz cans fit kitty cover quite well \n",
      "실제 요약 : cats like it \n",
      "예측 요약 :  my cat loves this\n",
      "\n",
      "\n",
      "원문 : candy become christmas tradition house family grows cut pieces smaller smaller sure wish candy available year round \n",
      "실제 요약 : hershey golden almond bar \n",
      "예측 요약 :  delicious\n",
      "\n",
      "\n",
      "원문 : purchased friend loves cook find paid times cans robbery know purchase one around far item brand paste excellent beef dish friend made using paste good ones thai restaurant would recommend paste price \n",
      "실제 요약 : great paste but way overpriced like more \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : got picky one year old attempt get eat fruits veggies like chunky textures yet got yesterday gave one soon opened box loved gone within seconds cannot wait try flavors \n",
      "실제 요약 : wish would have tried these \n",
      "예측 요약 :  great for babies\n",
      "\n",
      "\n",
      "원문 : guys make great alternative granolas banana apple cocoa cappucino aware last one contains large pieces coffee beans everybody sometimes appreciate option afternoon work anyways tasty filling alternative junk often reach hungry highly recommend \n",
      "실제 요약 : great alternative for or grain free snacking \n",
      "예측 요약 :  great for breakfast\n",
      "\n",
      "\n",
      "원문 : local store stopped carrying item ordered bulk via amazon price right taste great wife one needs gluten free mind gluten free long brand use others mushy tasteless \n",
      "실제 요약 : best gluten free pasta \n",
      "예측 요약 :  great bread\n",
      "\n",
      "\n",
      "원문 : tried pamela brownie mix recommendation relative celiac year diagnosed pretty disappointed although moist brownie like texture aftertaste like notice many gf baking mixes also agree comment tasting carob instead chocolatey non gf family friends said weird different terrible tasted one want another sticking brownie recipe using least family likes \n",
      "실제 요약 : brownie mix nothing to home about \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : like brand coconut oil great cook gives slight coconut flavor food baked good \n",
      "실제 요약 : great coconut oil \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : love hazelnut smell coffee figure also great cup hot chocolate unfortunately product give strong hazelnut feeling little well still good one \n",
      "실제 요약 : hazelnut \n",
      "예측 요약 :  good coffee\n",
      "\n",
      "\n",
      "원문 : best canned tomato soup market bar none best organic \n",
      "실제 요약 : best canned tomato soup on the market \n",
      "예측 요약 :  great soup\n",
      "\n",
      "\n",
      "원문 : stink cares dog treats dogs looove little tiny dogs issues little palates work great easy chew beg \n",
      "실제 요약 : my puppies love them \n",
      "예측 요약 :  my dogs love these\n",
      "\n",
      "\n",
      "원문 : love huge selection without buy entire box one kind gave chance try things would sometimes want try new flavor want spend money whole box come mint flavors toss mint severe trigger rest cups good \n",
      "실제 요약 : just my cup of tea \n",
      "예측 요약 :  great deal\n",
      "\n",
      "\n",
      "원문 : strawberry twizzlers guilty pleasure yummy six pounds around son \n",
      "실제 요약 : strawberry yummy \n",
      "예측 요약 :  great cookies\n",
      "\n",
      "\n",
      "원문 : found item puppy treats amazon received warning back said adult dogs \n",
      "실제 요약 : misleading \n",
      "예측 요약 :  my dog loves these\n",
      "\n",
      "\n",
      "원문 : daycare uses formula us try daughter likes tried name brands one seem upset stomach \n",
      "실제 요약 : best formula for my baby \n",
      "예측 요약 :  good but not great\n",
      "\n",
      "\n",
      "원문 : cracker seem healthy side hard rock buying \n",
      "실제 요약 : very unhappy \n",
      "예측 요약 :  crackers\n",
      "\n",
      "\n",
      "원문 : young cat went kidney failure regarding food water intake absolutely loves food looks every morning amazon makes getting breeze appreciate reviews led product really really likes \n",
      "실제 요약 : could not be more pleased \n",
      "예측 요약 :  great food\n",
      "\n",
      "\n",
      "원문 : read reviews see people thing things great many cant get texture initial smell bad able wash smell pretty well leaving mild fishy aftertaste texture awful nasty chewy fishy pasta good thing say stuff individual bags comes really small single serving size got bunch friends trick trying \n",
      "실제 요약 : had to try it but yuck \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : tried hazelnut flavored coffee brands far best bad auto ship \n",
      "실제 요약 : the best hazelnut out there \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : love erin breakfast cookies flavor little rich gives funny feeling back throat \n",
      "실제 요약 : not my favorite flavor \n",
      "예측 요약 :  great\n",
      "\n",
      "\n",
      "원문 : pretty good value compared buying store also notice smell strong dog enjoys medium sized dog chews one day two days update noticed dog getting loose stool color days thought maybe might rawhide stopped giving problem solved product sit well dog \n",
      "실제 요약 : good value but loose \n",
      "예측 요약 :  great toy\n",
      "\n",
      "\n",
      "원문 : love item keep reorder use workouts snack must try like \n",
      "실제 요약 : love one coconut water with \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : excellent hot chocolate love love hot chocolate go love would purchase \n",
      "실제 요약 : smooth \n",
      "예측 요약 :  hot cocoa\n",
      "\n",
      "\n",
      "원문 : good testing honey description claims true great product price \n",
      "실제 요약 : good honey \n",
      "예측 요약 :  not what expected\n",
      "\n",
      "\n",
      "원문 : kellogg products full gmos linked many health problems including cancer auto immune disease etc please research gmos deciding purchase products kellogg would never feed family \n",
      "실제 요약 : do not buy from kellogg \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : product cheap candy three dollar candy sold bucks dont waste money time \n",
      "실제 요약 : no good \n",
      "예측 요약 :  rip off\n",
      "\n",
      "\n",
      "원문 : family loves gummy frogs fresh soft open bag even time go stale finish long price fabulous automatic delivery every months highly recommended \n",
      "실제 요약 : yummy \n",
      "예측 요약 :  great cookies\n",
      "\n",
      "\n",
      "원문 : around great experience ordering dog food great price fast shipping \n",
      "실제 요약 : great \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : love stuff one best combinations chocolate mexican spice flavors tried used live near cafe made mochas cocoa buy home purpose also works really well add little spice cookies \n",
      "실제 요약 : my favorite \n",
      "예측 요약 :  great for\n",
      "\n",
      "\n",
      "원문 : one pack popcorn great cut end dump popcorn maker use stove top maker make mine though really need huge container make properly popcorn still popping empty contents bowl makes ton popcorn salty usually hold back little salt get perfect taste really like popcorn like popcorn movies \n",
      "실제 요약 : great american popcorn as described \n",
      "예측 요약 :  great popcorn\n",
      "\n",
      "\n",
      "원문 : sliced long way make nice strips fold eggs drop soup whatever add lot flavor hot use get even flavor good way make food lot interesting \n",
      "실제 요약 : excellent flavor good value \n",
      "예측 요약 :  great for lunch\n",
      "\n",
      "\n",
      "원문 : using product instead regular salt made difference health level \n",
      "실제 요약 : great product \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  salt\n",
      "\n",
      "\n",
      "원문 : used buy gerber baby foods thrilled started carrying organic foods discovered add gelatin disgusting absolutely nutritional value buying gerber products earth best actually organic \n",
      "실제 요약 : why do their organic foods contain \n",
      "예측 요약 :  yuck\n",
      "\n",
      "\n",
      "원문 : oreos gone quality little creme filling mostly chocolate cookie recommend newman equivalent much filling great tasting \n",
      "실제 요약 : little filling disappointed in quality of product \n",
      "예측 요약 :  great cookie\n",
      "\n",
      "\n",
      "원문 : recently heard organic white tea decided give try ordered amazon merchandise came timely fashion really good tea would recomend tea anyone since purchased several items amazon would order amazon \n",
      "실제 요약 : organic white tea \n",
      "예측 요약 :  good tea but\n",
      "\n",
      "\n",
      "원문 : works well keurig cofee maker always cups handy uses less space types holders glad ordered item \n",
      "실제 요약 : cup storage coffee for cups \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : best candy long time kind expensive good special occasions know know nutrition value candy taste exceptional \n",
      "실제 요약 : wow \n",
      "예측 요약 :  great candy\n",
      "\n",
      "\n",
      "원문 : zipfizz tastes good keeps moving day zipfizz loaded energy great lack required rest night \n",
      "실제 요약 : great for you on the go \n",
      "예측 요약 :  good stuff\n",
      "\n",
      "\n",
      "원문 : ordered online coworker loves chocolate basket arrived fast packed great presentation variety basket best looking great chocolate gift basket recommend one \n",
      "실제 요약 : perfect \n",
      "예측 요약 :  great gift\n",
      "\n",
      "\n",
      "원문 : tea fine taste indian spiced chai tea twinings used liked old one lot better could find \n",
      "실제 요약 : not the same \n",
      "예측 요약 :  not for me\n",
      "\n",
      "\n",
      "원문 : like eat lot meat great source protein eating lot fiber also great way stay healthy love cereal price amazon unbeatable especially goes sale \n",
      "실제 요약 : best high fiber high protein cereal out there \n",
      "예측 요약 :  healthy and tasty\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 결과가 출력이 되는데, 기존의 요약과는 다른 요약을 출력하면서도 원문의 내용을 담고 있는 의미있는 요약들이 보이네요. 심지어 일부 요약의 경우에는 원문에 없던 단어를 사용해서 요약을 하기도 하고 있어요. 워드 임베딩과 RNN의 콜라보로 이뤄낸 신기한 성과네요!\n",
    "\n",
    "물론 슬프게도 그다지 좋지 않은 요약의 예도 꽤나 보이기도 하네요. 성능을 개선하기 위해서는 seq2seq와 어텐션의 자체의 조합을 좀 더 좋게 수정하는 방법도 있고, 빔 서치(beam search), 사전 훈련된 워드 임베딩(pre-trained word embedding), 또는 인코더 - 디코더 자체의 구조를 새로이 변경한 하는 트랜스포머(Transformer)와 같은 여러 개선 방안들이 존재합니다. 이런 방안들에 대해서도 향후 살펴보게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추출적 요약 해보기\n",
    "앞서 seq2seq를 통해서 추상적 요약을 진행해봤어요. 그런데 텍스트 요약에는 추상적 요약 외에도 이미 본문에 존재하는 단어구, 문장을 뽑아서 요약으로 삼는 추출적 요약 방법도 있었죠.\n",
    "\n",
    "패키지 Summa에서는 추출적 요약을 위한 모듈인 summarize를 제공하고 있어 아주 간단하게 실습을 해볼 수 있어요. 영화 매트릭스 시놉시스를 요약해보면서 summarize 사용법을 익혀볼까요?\n",
    "\n",
    "### 패키지 설치\n",
    "먼저 필요한 패키지를 아래와 같이 설치해 주세요.\n",
    "\n",
    "- $ pip install summa\n",
    "\n",
    "### 데이터 다운로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매트릭스 시놉시스를 다운로드 해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 text에는 매트릭스 시놉시스가 문자열로 저장되어져 있어요. 출력 결과가 아주 길기 때문에 일부만 출력해보고, 잘 저장이 되었는지 확인해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summarize 사용하기\n",
    "Summa의 summarize()의 인자로 사용되는 값들에 대해서 알아볼게요.\n",
    "\n",
    "text (str) : 요약할 테스트. ratio (float, optional) – 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값 words (int or None, optional) – 출력에 포함할 단어 수. 만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다. split (bool, optional) – True면 문장 list / False는 조인(join)된 문자열을 반환\n",
    "\n",
    "Summa의 summarize는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행해요. 그렇기 때문에 문장 구분이 되어있지 않은 원문을 바로 입력으로 넣을 수 있어요. 비율을 적게 주어서 요약문으로 선택되는 문장의 개수를 줄여볼게요. 원문의 0.005%만을 출력해도록 설정했어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 리스트로 출력 결과를 받고 싶다면 split 인자의 값을 True로 하면 돼요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어의 수로 요약문의 크기를 조절할 수도 있어요. 단어를 50개만 선택하도록 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트: 뉴스기사 요약해보기\n",
    "새로운 데이터셋에 대해서 추상적 요약과 추출적 요약을 모두 해보는 시간을 가져봐요.\n",
    "\n",
    "### Step 1. 데이터 수집하기\n",
    "데이터는 아래 링크에 있는 뉴스 기사 데이터(newssummarymore.csv)를 사용하세요.\n",
    "sunnysai12345/News_Summary\n",
    "\n",
    "아래의 코드로 데이터를 다운로드 할 수 있어요.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터는 기사의 본문에 해당되는 text와 headlines 두 가지 열로 구성되어져 있습니다.\n",
    "\n",
    "추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 삼아서 모델을 학습할 수 있어요. 추출적 요약을 하는 경우에는 오직 text열만을 사용하세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "실습에서 사용된 전처리를 참고하여 각자 필요하다고 생각하는 전처리를 추가 사용하여 텍스트를 정규화 또는 정제해 보세요. 만약, 불용어 제거를 선택한다면 상대적으로 길이가 짧은 요약 데이터에 대해서도 불용어를 제거하는 것이 좋을지 고민해보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)\n",
    "일반적인 seq2seq보다는 어텐션 메커니즘을 사용한 seq2seq를 사용하는 것이 더 나은 성능을 얻을 수 있어요. 실습 내용을 참고하여 어텐션 메커니즘을 사용한 seq2seq를 설계해 보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)\n",
    "원래의 요약문(headlines 열)과 학습을 통해 얻은 추상적 요약의 결과를 비교해보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Summa을 이용해서 추출적 요약해보기\n",
    "추상적 요약은 추출적 요약과는 달리 문장의 표현력을 다양하게 가져갈 수 있지만, 추출적 요약에 비해서 난이도가 높아요. 반대로 말하면 추출적 요약은 추상적 요약에 비해 난이도가 낮고 기존 문장에서 문장을 꺼내오는 것이므로 잘못된 요약이 나올 가능성이 낮아요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summa의 summarize를 사용하여 추출적 요약을 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "평가문항\t상세기준\n",
    "1. Abstractive 모델 구성을 위한 텍스트 전처리 단계가 체계적으로 진행되었다.\n",
    ": 분석단계, 정제단계, 정규화와 불용어 제거, 데이터셋 분리, 인코딩 과정이 빠짐없이 체계적으로 진행되었다.\n",
    "\n",
    "2. 텍스트 요약모델이 성공적으로 학습되었음을 확인하였다.\n",
    ": 모델학습이 안정적으로 수렴되었음을 그래프를 통해 확인하였으며, 실제 요약문과 유사한 요약문장을 얻을 수 있었다.\n",
    "\n",
    "3. Extractive 요약을 시도해 보고 Abstractive 요약 결과과 함께 비교해 보았다.\n",
    ": 두 요약 결과를 문법완성도 측면과 핵심단어 포함 측면으로 나누어 비교분석 결과를 제시하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
